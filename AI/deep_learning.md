
<br>
<br>

# `#Deep Learning:` 

<br>


<br>

# `#01: Deep Learning Introduction:`

<br>


## Position of Deep Learning In AI:

![image](image/img01.png)


<br>

## Why Deep Learning:

![image](image/img02.png)

<br>


<br>

# `#02: Introduction To ANN:`

<br>


![image](image/img03.png)

<br>

![image](image/img04.png)


<br>

## **Perceptron:**

![image](image/img06.png)

<br>

## **ANN Or MultiLayer Perceptron**

![image](image/image05.jpg)


<br>
<br>

# `#03: How Newral Network Works:`

<br>
<br>

- ## Forward Propagation

![image](image/image07.jpg)


## **Loss Fuction:**
![image](image/img09.png)

- ## Backword Propagation and Optimizer:
![image](image/image07.jpg)


- ## How Optimizer Update Parameter:

<br>

![image](image/img08.png)

<br>

**Loss Function With Features**
![image](image/img07.png)


<br>



<br>
<br>

# `#04: CNN,LSTM,GRU,Transformer:`

<br>
<br>

![image](image/img11.png)

<br>

![image](image/img10.png)


### -> ANN TABULAR DATA, CNN-> IMAGE, RNN->SEQUENTIAL DATA 
### -> Solve SEQUENTIAL DATA PROBLEM WITH ANN

![image](image/image07.jpg)


<br>

- Input Text (very in size)
- Zero Padding 
- Prediction Problem 
- Totally Discard the Sequence

<br>

![image](image/image07.jpg)

<br>

![image](image/img12.png)

<br>

### Major Proble with RNN
- Long Term Dependency:
- Exploding Gradient Descent 


<br>

### LSTM

![image](image/img13.png)

<br>

![image](image/image08.jpg)

<br>

### GRU:

![image](image/img14.png)


<br>
<br>


# ![work](https://github.com/yasin-arafat-05/100DaysDL)


<br>
<br>

